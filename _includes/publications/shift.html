{% include base_path %}


<!-- SHIFT -->
<tr>
  <td rowspan="5" class="center" style="width: 400px;"><img src="images/thumbnails/shift.jpeg" alt="shift" style="width:400px; height:auto;"></td>
  <td class="bold">SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation</td>
  </tr>
  <tr>
  <td class="italic">Tao Sun*, <span style="text-decoration: underline;">Mattia Segu</span>*, Janis Postels, Yuxuan Wang, Luc Van Gool, Bernt Schiele, Federico Tombari, Fisher Yu</td>
  </tr>
  <tr>
  <td class="thin">Conference on Computer Vision and Pattern Recognition (CVPR), 2022</td>
  </tr>
  <tr>
  <td style="text-align: justify">Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous-driving systems. Existing image-and video-based driving datasets, however, fall short of capturing the mutable nature of the real world. In this paper, we introduce the largest synthetic dataset for autonomous driving, SHIFT. It presents discrete and continuous shifts in cloudiness, rain and fog intensity, time of day, and vehicle and pedestrian density. Featuring a comprehensive sensor suite and annotations for several mainstream perception tasks, SHIFT allows to investigate how a perception systems' performance degrades at increasing levels of domain shift, fostering the development of continuous adaptation strategies to mitigate this problem and assessing the robustness and generality of a model.</td>
  </tr>
  <tr>
  <td style="padding-bottom: 5px;">
    <a href="https://arxiv.org/abs/2206.08367">[arXiv]</a>
    <a href="http://openaccess.thecvf.com/content/CVPR2022/papers/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.pdf">[CVPR 2022 Paper]</a>
    <a href="https://www.vis.xyz/shift">[Project]</a>
  </td>
  </tr>